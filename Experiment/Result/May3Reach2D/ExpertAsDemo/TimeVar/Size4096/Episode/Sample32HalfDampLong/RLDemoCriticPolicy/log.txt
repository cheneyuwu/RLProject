Logging to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy/
Launching the training process with 1 cpu core(s).
Setting log level to 2.
Using environment Reach2D with r scale down by 1.000000 shift by 0.500000 and max episode 0.000000
Skip demonstration training.
Will use provided policy file from /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/DemoCriticOnly/rl_demo_critic/policy_latest.pkl.
Creating a Demonstration NN.
Creating an Ensemble NN of sample x hidden x layer: 32 x 256 x 3.
*** her_params ***
k: 4
reward_fun: <function configure_her.<locals>.reward_fun at 0x7f2c789d9598>
strategy: future
*** her_params ***
*** ddpg_params ***
Q_lr: 0.001
T: 42
action_l2: 0.5
aux_loss_weight: 0.0078
batch_size: 256
batch_size_demo: 128
buffer_size: 1000000
ca_ratio: 1
clip_obs: 200.0
clip_pos_returns: False
clip_return: 41.99999999999995
demo_strategy: critic
gamma: 0.9761904761904762
hidden: 256
info: {'env_name': 'Reach2D', 'r_scale': 1.0, 'r_shift': 0.5, 'eps_length': 0}
input_dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
layers: 3
max_u: 2
norm_clip: 5
norm_eps: 0.01
num_demo: 1000
num_sample: 1
pi_lr: 0.001
polyak: 0.95
prm_loss_weight: 0.001
q_filter: 0
relative_goals: False
rollout_batch_size: 4
sample_transitions: <function make_sample_her_transitions.<locals>._sample_her_transitions at 0x7f2be18a5950>
scope: ddpg
subtract_goals: <function simple_goal_subtract at 0x7f2c789d5620>
*** ddpg_params ***
Configuring the replay buffer.
Preparing staging area for feeding data to the model.
Creating a DDPG agent with action space 2 x 2.

*** rollout_params ***
T: 42
compute_Q: False
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 0
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 4
use_demo_states: True
use_target_net: False
*** rollout_params ***
*** eval_params ***
T: 42
compute_Q: True
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 1
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 20
use_demo_states: False
use_target_net: False
*** eval_params ***
Training the RL agent.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 0            |
| stats_g/mean       | 0.015789717  |
| stats_g/std        | 1.258781     |
| stats_o/mean       | 0.0058608055 |
| stats_o/std        | 0.8224132    |
| test/episode       | 20.0         |
| test/mean_Q        | 5.703841     |
| test/success_rate  | 0.45         |
| train/episode      | 40.0         |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.45.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_0.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 1          |
| stats_g/mean       | 0.14246783 |
| stats_g/std        | 1.393908   |
| stats_o/mean       | 0.07638363 |
| stats_o/std        | 0.8872397  |
| test/episode       | 40.0       |
| test/mean_Q        | 1.2483914  |
| test/success_rate  | 0.25       |
| train/episode      | 80.0       |
| train/success_rate | 0.0        |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 2          |
| stats_g/mean       | 0.23460719 |
| stats_g/std        | 2.0736642  |
| stats_o/mean       | 0.12704712 |
| stats_o/std        | 1.248891   |
| test/episode       | 60.0       |
| test/mean_Q        | 8.536189   |
| test/success_rate  | 0.4        |
| train/episode      | 120.0      |
| train/success_rate | 0.0        |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_2.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 3          |
| stats_g/mean       | 0.20267414 |
| stats_g/std        | 2.017195   |
| stats_o/mean       | 0.1134697  |
| stats_o/std        | 1.2156398  |
| test/episode       | 80.0       |
| test/mean_Q        | 6.4843345  |
| test/success_rate  | 0.45       |
| train/episode      | 160.0      |
| train/success_rate | 0.05       |
-----------------------------------
New best success rate: 0.45.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 4          |
| stats_g/mean       | 0.20200758 |
| stats_g/std        | 1.8665662  |
| stats_o/mean       | 0.11399311 |
| stats_o/std        | 1.1330639  |
| test/episode       | 100.0      |
| test/mean_Q        | 8.555631   |
| test/success_rate  | 0.5        |
| train/episode      | 200.0      |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.5.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_4.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 5          |
| stats_g/mean       | 0.18499056 |
| stats_g/std        | 1.7681048  |
| stats_o/mean       | 0.10397094 |
| stats_o/std        | 1.080916   |
| test/episode       | 120.0      |
| test/mean_Q        | 11.260099  |
| test/success_rate  | 0.8        |
| train/episode      | 240.0      |
| train/success_rate | 0.075      |
-----------------------------------
New best success rate: 0.8.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 6          |
| stats_g/mean       | 0.19417076 |
| stats_g/std        | 1.6803342  |
| stats_o/mean       | 0.10684266 |
| stats_o/std        | 1.033889   |
| test/episode       | 140.0      |
| test/mean_Q        | 10.878966  |
| test/success_rate  | 0.6        |
| train/episode      | 280.0      |
| train/success_rate | 0.0        |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_6.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 7          |
| stats_g/mean       | 0.18505263 |
| stats_g/std        | 1.5903628  |
| stats_o/mean       | 0.10183722 |
| stats_o/std        | 0.98586965 |
| test/episode       | 160.0      |
| test/mean_Q        | 9.824815   |
| test/success_rate  | 0.65       |
| train/episode      | 320.0      |
| train/success_rate | 0.125      |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 8          |
| stats_g/mean       | 0.16953573 |
| stats_g/std        | 1.5234075  |
| stats_o/mean       | 0.09254867 |
| stats_o/std        | 0.9513643  |
| test/episode       | 180.0      |
| test/mean_Q        | 11.784163  |
| test/success_rate  | 0.7        |
| train/episode      | 360.0      |
| train/success_rate | 0.1        |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_8.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 9          |
| stats_g/mean       | 0.1661353  |
| stats_g/std        | 1.463146   |
| stats_o/mean       | 0.09143715 |
| stats_o/std        | 0.92147887 |
| test/episode       | 200.0      |
| test/mean_Q        | 12.67956   |
| test/success_rate  | 0.9        |
| train/episode      | 400.0      |
| train/success_rate | 0.1        |
-----------------------------------
New best success rate: 0.9.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 10          |
| stats_g/mean       | 0.15001446  |
| stats_g/std        | 1.4086723   |
| stats_o/mean       | 0.082640596 |
| stats_o/std        | 0.8926846   |
| test/episode       | 220.0       |
| test/mean_Q        | 12.81097    |
| test/success_rate  | 0.95        |
| train/episode      | 440.0       |
| train/success_rate | 0.15        |
------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_10.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 11         |
| stats_g/mean       | 0.14081274 |
| stats_g/std        | 1.3612001  |
| stats_o/mean       | 0.07707289 |
| stats_o/std        | 0.86743844 |
| test/episode       | 240.0      |
| test/mean_Q        | 13.119156  |
| test/success_rate  | 0.95       |
| train/episode      | 480.0      |
| train/success_rate | 0.225      |
-----------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 12         |
| stats_g/mean       | 0.13196626 |
| stats_g/std        | 1.3201923  |
| stats_o/mean       | 0.07277085 |
| stats_o/std        | 0.84568834 |
| test/episode       | 260.0      |
| test/mean_Q        | 11.97905   |
| test/success_rate  | 0.95       |
| train/episode      | 520.0      |
| train/success_rate | 0.325      |
-----------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_12.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 13         |
| stats_g/mean       | 0.12357301 |
| stats_g/std        | 1.2831423  |
| stats_o/mean       | 0.06738626 |
| stats_o/std        | 0.82716715 |
| test/episode       | 280.0      |
| test/mean_Q        | 13.622997  |
| test/success_rate  | 1.0        |
| train/episode      | 560.0      |
| train/success_rate | 0.2        |
-----------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 14         |
| stats_g/mean       | 0.11416652 |
| stats_g/std        | 1.2505517  |
| stats_o/mean       | 0.06267298 |
| stats_o/std        | 0.81071186 |
| test/episode       | 300.0      |
| test/mean_Q        | 12.282895  |
| test/success_rate  | 0.65       |
| train/episode      | 600.0      |
| train/success_rate | 0.25       |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_14.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 15         |
| stats_g/mean       | 0.11239913 |
| stats_g/std        | 1.2225436  |
| stats_o/mean       | 0.0616787  |
| stats_o/std        | 0.7965133  |
| test/episode       | 320.0      |
| test/mean_Q        | 12.212557  |
| test/success_rate  | 0.7        |
| train/episode      | 640.0      |
| train/success_rate | 0.2        |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 16          |
| stats_g/mean       | 0.1015206   |
| stats_g/std        | 1.1954547   |
| stats_o/mean       | 0.056323975 |
| stats_o/std        | 0.7833734   |
| test/episode       | 340.0       |
| test/mean_Q        | 13.915941   |
| test/success_rate  | 0.8         |
| train/episode      | 680.0       |
| train/success_rate | 0.35        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_16.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 17          |
| stats_g/mean       | 0.092934296 |
| stats_g/std        | 1.1721908   |
| stats_o/mean       | 0.051790692 |
| stats_o/std        | 0.7721002   |
| test/episode       | 360.0       |
| test/mean_Q        | 11.716302   |
| test/success_rate  | 0.6         |
| train/episode      | 720.0       |
| train/success_rate | 0.175       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 18          |
| stats_g/mean       | 0.089001186 |
| stats_g/std        | 1.1514231   |
| stats_o/mean       | 0.049439635 |
| stats_o/std        | 0.76359785  |
| test/episode       | 380.0       |
| test/mean_Q        | 11.552168   |
| test/success_rate  | 0.65        |
| train/episode      | 760.0       |
| train/success_rate | 0.125       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_18.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 19          |
| stats_g/mean       | 0.091356486 |
| stats_g/std        | 1.1318308   |
| stats_o/mean       | 0.050574493 |
| stats_o/std        | 0.7545732   |
| test/episode       | 400.0       |
| test/mean_Q        | 12.018925   |
| test/success_rate  | 0.75        |
| train/episode      | 800.0       |
| train/success_rate | 0.05        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 20          |
| stats_g/mean       | 0.09321565  |
| stats_g/std        | 1.1131754   |
| stats_o/mean       | 0.051778555 |
| stats_o/std        | 0.7452363   |
| test/episode       | 420.0       |
| test/mean_Q        | 11.180436   |
| test/success_rate  | 0.9         |
| train/episode      | 840.0       |
| train/success_rate | 0.2         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_20.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 21          |
| stats_g/mean       | 0.087253034 |
| stats_g/std        | 1.0956168   |
| stats_o/mean       | 0.04802777  |
| stats_o/std        | 0.7374564   |
| test/episode       | 440.0       |
| test/mean_Q        | 11.4251     |
| test/success_rate  | 0.65        |
| train/episode      | 880.0       |
| train/success_rate | 0.1         |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 22         |
| stats_g/mean       | 0.08007669 |
| stats_g/std        | 1.0804378  |
| stats_o/mean       | 0.04422699 |
| stats_o/std        | 0.7307897  |
| test/episode       | 460.0      |
| test/mean_Q        | 12.319253  |
| test/success_rate  | 0.85       |
| train/episode      | 920.0      |
| train/success_rate | 0.05       |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_22.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 23         |
| stats_g/mean       | 0.07814979 |
| stats_g/std        | 1.0665282  |
| stats_o/mean       | 0.04295946 |
| stats_o/std        | 0.72454625 |
| test/episode       | 480.0      |
| test/mean_Q        | 11.960147  |
| test/success_rate  | 0.65       |
| train/episode      | 960.0      |
| train/success_rate | 0.15       |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 24         |
| stats_g/mean       | 0.07464473 |
| stats_g/std        | 1.0539505  |
| stats_o/mean       | 0.04111948 |
| stats_o/std        | 0.71908784 |
| test/episode       | 500.0      |
| test/mean_Q        | 11.8376045 |
| test/success_rate  | 0.6        |
| train/episode      | 1000.0     |
| train/success_rate | 0.075      |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_24.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 25         |
| stats_g/mean       | 0.07338001 |
| stats_g/std        | 1.0407838  |
| stats_o/mean       | 0.04062272 |
| stats_o/std        | 0.7135786  |
| test/episode       | 520.0      |
| test/mean_Q        | 12.66918   |
| test/success_rate  | 0.75       |
| train/episode      | 1040.0     |
| train/success_rate | 0.1        |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 26         |
| stats_g/mean       | 0.06733613 |
| stats_g/std        | 1.0291417  |
| stats_o/mean       | 0.03732966 |
| stats_o/std        | 0.7083714  |
| test/episode       | 540.0      |
| test/mean_Q        | 11.55507   |
| test/success_rate  | 0.6        |
| train/episode      | 1080.0     |
| train/success_rate | 0.025      |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_26.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 27          |
| stats_g/mean       | 0.06806421  |
| stats_g/std        | 1.0196326   |
| stats_o/mean       | 0.037633322 |
| stats_o/std        | 0.7047428   |
| test/episode       | 560.0       |
| test/mean_Q        | 11.094277   |
| test/success_rate  | 0.65        |
| train/episode      | 1120.0      |
| train/success_rate | 0.05        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 28         |
| stats_g/mean       | 0.06341223 |
| stats_g/std        | 1.010594   |
| stats_o/mean       | 0.03527425 |
| stats_o/std        | 0.7014229  |
| test/episode       | 580.0      |
| test/mean_Q        | 11.182859  |
| test/success_rate  | 0.55       |
| train/episode      | 1160.0     |
| train/success_rate | 0.1        |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_28.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 29          |
| stats_g/mean       | 0.063007064 |
| stats_g/std        | 1.0009264   |
| stats_o/mean       | 0.03486193  |
| stats_o/std        | 0.69747645  |
| test/episode       | 600.0       |
| test/mean_Q        | 10.766704   |
| test/success_rate  | 0.75        |
| train/episode      | 1200.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 30          |
| stats_g/mean       | 0.061468616 |
| stats_g/std        | 0.9904312   |
| stats_o/mean       | 0.033678647 |
| stats_o/std        | 0.6926633   |
| test/episode       | 620.0       |
| test/mean_Q        | 12.0543785  |
| test/success_rate  | 0.6         |
| train/episode      | 1240.0      |
| train/success_rate | 0.1         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_30.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 31          |
| stats_g/mean       | 0.060439844 |
| stats_g/std        | 0.9802687   |
| stats_o/mean       | 0.0331548   |
| stats_o/std        | 0.6880333   |
| test/episode       | 640.0       |
| test/mean_Q        | 13.0537815  |
| test/success_rate  | 0.6         |
| train/episode      | 1280.0      |
| train/success_rate | 0.025       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 32          |
| stats_g/mean       | 0.056449257 |
| stats_g/std        | 0.9725023   |
| stats_o/mean       | 0.030924292 |
| stats_o/std        | 0.68488705  |
| test/episode       | 660.0       |
| test/mean_Q        | 12.413765   |
| test/success_rate  | 0.7         |
| train/episode      | 1320.0      |
| train/success_rate | 0.025       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_32.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 33          |
| stats_g/mean       | 0.05242391  |
| stats_g/std        | 0.96328485  |
| stats_o/mean       | 0.028765857 |
| stats_o/std        | 0.6802975   |
| test/episode       | 680.0       |
| test/mean_Q        | 13.16255    |
| test/success_rate  | 0.8         |
| train/episode      | 1360.0      |
| train/success_rate | 0.125       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 34          |
| stats_g/mean       | 0.047869317 |
| stats_g/std        | 0.9559834   |
| stats_o/mean       | 0.026480261 |
| stats_o/std        | 0.67775595  |
| test/episode       | 700.0       |
| test/mean_Q        | 14.208345   |
| test/success_rate  | 0.95        |
| train/episode      | 1400.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_34.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 35          |
| stats_g/mean       | 0.048760474 |
| stats_g/std        | 0.9469896   |
| stats_o/mean       | 0.026833616 |
| stats_o/std        | 0.67342895  |
| test/episode       | 720.0       |
| test/mean_Q        | 11.317441   |
| test/success_rate  | 0.9         |
| train/episode      | 1440.0      |
| train/success_rate | 0.15        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 36          |
| stats_g/mean       | 0.045760892 |
| stats_g/std        | 0.9398447   |
| stats_o/mean       | 0.025403237 |
| stats_o/std        | 0.67066574  |
| test/episode       | 740.0       |
| test/mean_Q        | 11.898982   |
| test/success_rate  | 0.85        |
| train/episode      | 1480.0      |
| train/success_rate | 0.1         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_36.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 37          |
| stats_g/mean       | 0.043196216 |
| stats_g/std        | 0.9322852   |
| stats_o/mean       | 0.023795856 |
| stats_o/std        | 0.6666727   |
| test/episode       | 760.0       |
| test/mean_Q        | 13.377818   |
| test/success_rate  | 0.8         |
| train/episode      | 1520.0      |
| train/success_rate | 0.15        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 38          |
| stats_g/mean       | 0.038913615 |
| stats_g/std        | 0.92483056  |
| stats_o/mean       | 0.021404834 |
| stats_o/std        | 0.66315085  |
| test/episode       | 780.0       |
| test/mean_Q        | 14.39442    |
| test/success_rate  | 1.0         |
| train/episode      | 1560.0      |
| train/success_rate | 0.175       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_38.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 39          |
| stats_g/mean       | 0.036051996 |
| stats_g/std        | 0.91871595  |
| stats_o/mean       | 0.019943194 |
| stats_o/std        | 0.6605556   |
| test/episode       | 800.0       |
| test/mean_Q        | 13.194443   |
| test/success_rate  | 0.75        |
| train/episode      | 1600.0      |
| train/success_rate | 0.05        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 40          |
| stats_g/mean       | 0.03562826  |
| stats_g/std        | 0.9128704   |
| stats_o/mean       | 0.019816749 |
| stats_o/std        | 0.6577991   |
| test/episode       | 820.0       |
| test/mean_Q        | 13.635469   |
| test/success_rate  | 0.9         |
| train/episode      | 1640.0      |
| train/success_rate | 0.05        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_40.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 41          |
| stats_g/mean       | 0.03828993  |
| stats_g/std        | 0.90723944  |
| stats_o/mean       | 0.020783722 |
| stats_o/std        | 0.65572757  |
| test/episode       | 840.0       |
| test/mean_Q        | 12.38483    |
| test/success_rate  | 1.0         |
| train/episode      | 1680.0      |
| train/success_rate | 0.05        |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 42          |
| stats_g/mean       | 0.036788158 |
| stats_g/std        | 0.9017244   |
| stats_o/mean       | 0.019849988 |
| stats_o/std        | 0.6532234   |
| test/episode       | 860.0       |
| test/mean_Q        | 12.554937   |
| test/success_rate  | 0.95        |
| train/episode      | 1720.0      |
| train/success_rate | 0.175       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_42.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 43          |
| stats_g/mean       | 0.033979908 |
| stats_g/std        | 0.8962604   |
| stats_o/mean       | 0.018715024 |
| stats_o/std        | 0.6510692   |
| test/episode       | 880.0       |
| test/mean_Q        | 12.320194   |
| test/success_rate  | 1.0         |
| train/episode      | 1760.0      |
| train/success_rate | 0.1         |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 44          |
| stats_g/mean       | 0.03511516  |
| stats_g/std        | 0.8910841   |
| stats_o/mean       | 0.019198054 |
| stats_o/std        | 0.648806    |
| test/episode       | 900.0       |
| test/mean_Q        | 11.805195   |
| test/success_rate  | 0.85        |
| train/episode      | 1800.0      |
| train/success_rate | 0.15        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_44.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 45          |
| stats_g/mean       | 0.03363216  |
| stats_g/std        | 0.8864764   |
| stats_o/mean       | 0.018409697 |
| stats_o/std        | 0.64641666  |
| test/episode       | 920.0       |
| test/mean_Q        | 10.845592   |
| test/success_rate  | 0.85        |
| train/episode      | 1840.0      |
| train/success_rate | 0.225       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 46          |
| stats_g/mean       | 0.032442324 |
| stats_g/std        | 0.8822968   |
| stats_o/mean       | 0.017751334 |
| stats_o/std        | 0.64479685  |
| test/episode       | 940.0       |
| test/mean_Q        | 12.1830225  |
| test/success_rate  | 1.0         |
| train/episode      | 1880.0      |
| train/success_rate | 0.1         |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_46.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 47          |
| stats_g/mean       | 0.036212713 |
| stats_g/std        | 0.8776332   |
| stats_o/mean       | 0.019704832 |
| stats_o/std        | 0.64219946  |
| test/episode       | 960.0       |
| test/mean_Q        | 12.998      |
| test/success_rate  | 0.95        |
| train/episode      | 1920.0      |
| train/success_rate | 0.225       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 48          |
| stats_g/mean       | 0.038685255 |
| stats_g/std        | 0.87358665  |
| stats_o/mean       | 0.020646395 |
| stats_o/std        | 0.64017224  |
| test/episode       | 980.0       |
| test/mean_Q        | 13.173153   |
| test/success_rate  | 0.95        |
| train/episode      | 1960.0      |
| train/success_rate | 0.175       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_48.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 49          |
| stats_g/mean       | 0.038192287 |
| stats_g/std        | 0.86949366  |
| stats_o/mean       | 0.020495456 |
| stats_o/std        | 0.6380636   |
| test/episode       | 1000.0      |
| test/mean_Q        | 12.060738   |
| test/success_rate  | 0.95        |
| train/episode      | 2000.0      |
| train/success_rate | 0.2         |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 50          |
| stats_g/mean       | 0.03804445  |
| stats_g/std        | 0.86598194  |
| stats_o/mean       | 0.020556958 |
| stats_o/std        | 0.6364972   |
| test/episode       | 1020.0      |
| test/mean_Q        | 11.594555   |
| test/success_rate  | 0.95        |
| train/episode      | 2040.0      |
| train/success_rate | 0.15        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_50.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 51          |
| stats_g/mean       | 0.03658274  |
| stats_g/std        | 0.8609496   |
| stats_o/mean       | 0.019724205 |
| stats_o/std        | 0.63393855  |
| test/episode       | 1040.0      |
| test/mean_Q        | 13.000428   |
| test/success_rate  | 0.75        |
| train/episode      | 2080.0      |
| train/success_rate | 0.175       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 52          |
| stats_g/mean       | 0.035375    |
| stats_g/std        | 0.85717916  |
| stats_o/mean       | 0.019032408 |
| stats_o/std        | 0.63202333  |
| test/episode       | 1060.0      |
| test/mean_Q        | 12.6126585  |
| test/success_rate  | 0.95        |
| train/episode      | 2120.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_52.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 53          |
| stats_g/mean       | 0.036301907 |
| stats_g/std        | 0.8534399   |
| stats_o/mean       | 0.019386368 |
| stats_o/std        | 0.63037145  |
| test/episode       | 1080.0      |
| test/mean_Q        | 13.996745   |
| test/success_rate  | 1.0         |
| train/episode      | 2160.0      |
| train/success_rate | 0.125       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 54          |
| stats_g/mean       | 0.035685062 |
| stats_g/std        | 0.84990287  |
| stats_o/mean       | 0.019142907 |
| stats_o/std        | 0.6292927   |
| test/episode       | 1100.0      |
| test/mean_Q        | 15.413685   |
| test/success_rate  | 1.0         |
| train/episode      | 2200.0      |
| train/success_rate | 0.075       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_54.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 55          |
| stats_g/mean       | 0.036221962 |
| stats_g/std        | 0.84675336  |
| stats_o/mean       | 0.019614909 |
| stats_o/std        | 0.6279949   |
| test/episode       | 1120.0      |
| test/mean_Q        | 12.370036   |
| test/success_rate  | 0.85        |
| train/episode      | 2240.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 56          |
| stats_g/mean       | 0.033817098 |
| stats_g/std        | 0.8435086   |
| stats_o/mean       | 0.018317424 |
| stats_o/std        | 0.62654555  |
| test/episode       | 1140.0      |
| test/mean_Q        | 12.807462   |
| test/success_rate  | 0.7         |
| train/episode      | 2280.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_56.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 57          |
| stats_g/mean       | 0.033854563 |
| stats_g/std        | 0.8407484   |
| stats_o/mean       | 0.018522678 |
| stats_o/std        | 0.6251407   |
| test/episode       | 1160.0      |
| test/mean_Q        | 12.386539   |
| test/success_rate  | 0.85        |
| train/episode      | 2320.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 58          |
| stats_g/mean       | 0.032938305 |
| stats_g/std        | 0.83776534  |
| stats_o/mean       | 0.018148744 |
| stats_o/std        | 0.623838    |
| test/episode       | 1180.0      |
| test/mean_Q        | 12.479825   |
| test/success_rate  | 0.9         |
| train/episode      | 2360.0      |
| train/success_rate | 0.025       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_58.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 59          |
| stats_g/mean       | 0.03151775  |
| stats_g/std        | 0.8344412   |
| stats_o/mean       | 0.017383344 |
| stats_o/std        | 0.6226572   |
| test/episode       | 1200.0      |
| test/mean_Q        | 12.480571   |
| test/success_rate  | 0.75        |
| train/episode      | 2400.0      |
| train/success_rate | 0.05        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 60          |
| stats_g/mean       | 0.03227052  |
| stats_g/std        | 0.83088696  |
| stats_o/mean       | 0.017702568 |
| stats_o/std        | 0.62133354  |
| test/episode       | 1220.0      |
| test/mean_Q        | 12.547874   |
| test/success_rate  | 0.7         |
| train/episode      | 2440.0      |
| train/success_rate | 0.125       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_60.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 61         |
| stats_g/mean       | 0.03269091 |
| stats_g/std        | 0.8277193  |
| stats_o/mean       | 0.01765844 |
| stats_o/std        | 0.6199679  |
| test/episode       | 1240.0     |
| test/mean_Q        | 13.650716  |
| test/success_rate  | 0.9        |
| train/episode      | 2480.0     |
| train/success_rate | 0.1        |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 62          |
| stats_g/mean       | 0.033045564 |
| stats_g/std        | 0.8248036   |
| stats_o/mean       | 0.01776013  |
| stats_o/std        | 0.6185701   |
| test/episode       | 1260.0      |
| test/mean_Q        | 13.879478   |
| test/success_rate  | 0.95        |
| train/episode      | 2520.0      |
| train/success_rate | 0.2         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_62.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 63          |
| stats_g/mean       | 0.032394573 |
| stats_g/std        | 0.82212245  |
| stats_o/mean       | 0.017291509 |
| stats_o/std        | 0.6174734   |
| test/episode       | 1280.0      |
| test/mean_Q        | 13.253769   |
| test/success_rate  | 0.95        |
| train/episode      | 2560.0      |
| train/success_rate | 0.05        |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 64          |
| stats_g/mean       | 0.032476887 |
| stats_g/std        | 0.819337    |
| stats_o/mean       | 0.017259536 |
| stats_o/std        | 0.6161435   |
| test/episode       | 1300.0      |
| test/mean_Q        | 14.336817   |
| test/success_rate  | 0.9         |
| train/episode      | 2600.0      |
| train/success_rate | 0.075       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_64.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 65         |
| stats_g/mean       | 0.03288255 |
| stats_g/std        | 0.816675   |
| stats_o/mean       | 0.01742283 |
| stats_o/std        | 0.61481786 |
| test/episode       | 1320.0     |
| test/mean_Q        | 13.685882  |
| test/success_rate  | 0.9        |
| train/episode      | 2640.0     |
| train/success_rate | 0.1        |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 66          |
| stats_g/mean       | 0.033039756 |
| stats_g/std        | 0.81341743  |
| stats_o/mean       | 0.017405925 |
| stats_o/std        | 0.61351144  |
| test/episode       | 1340.0      |
| test/mean_Q        | 13.660017   |
| test/success_rate  | 0.9         |
| train/episode      | 2680.0      |
| train/success_rate | 0.25        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_66.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 67          |
| stats_g/mean       | 0.03296728  |
| stats_g/std        | 0.8113595   |
| stats_o/mean       | 0.017389387 |
| stats_o/std        | 0.61279744  |
| test/episode       | 1360.0      |
| test/mean_Q        | 12.707267   |
| test/success_rate  | 0.85        |
| train/episode      | 2720.0      |
| train/success_rate | 0.175       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 68          |
| stats_g/mean       | 0.032267123 |
| stats_g/std        | 0.80911154  |
| stats_o/mean       | 0.016969586 |
| stats_o/std        | 0.6117523   |
| test/episode       | 1380.0      |
| test/mean_Q        | 14.559361   |
| test/success_rate  | 1.0         |
| train/episode      | 2760.0      |
| train/success_rate | 0.05        |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_68.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 69          |
| stats_g/mean       | 0.030178104 |
| stats_g/std        | 0.80678356  |
| stats_o/mean       | 0.015885849 |
| stats_o/std        | 0.6107774   |
| test/episode       | 1400.0      |
| test/mean_Q        | 14.004404   |
| test/success_rate  | 1.0         |
| train/episode      | 2800.0      |
| train/success_rate | 0.2         |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 70          |
| stats_g/mean       | 0.029667586 |
| stats_g/std        | 0.8052336   |
| stats_o/mean       | 0.015715802 |
| stats_o/std        | 0.61043096  |
| test/episode       | 1420.0      |
| test/mean_Q        | 13.731584   |
| test/success_rate  | 0.95        |
| train/episode      | 2840.0      |
| train/success_rate | 0.15        |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_70.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 71          |
| stats_g/mean       | 0.02792459  |
| stats_g/std        | 0.80325925  |
| stats_o/mean       | 0.014681708 |
| stats_o/std        | 0.60988426  |
| test/episode       | 1440.0      |
| test/mean_Q        | 13.939025   |
| test/success_rate  | 1.0         |
| train/episode      | 2880.0      |
| train/success_rate | 0.125       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 72          |
| stats_g/mean       | 0.029013317 |
| stats_g/std        | 0.8013277   |
| stats_o/mean       | 0.01515781  |
| stats_o/std        | 0.6090367   |
| test/episode       | 1460.0      |
| test/mean_Q        | 14.120811   |
| test/success_rate  | 1.0         |
| train/episode      | 2920.0      |
| train/success_rate | 0.1         |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_72.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 73          |
| stats_g/mean       | 0.02715128  |
| stats_g/std        | 0.79958415  |
| stats_o/mean       | 0.014365844 |
| stats_o/std        | 0.608178    |
| test/episode       | 1480.0      |
| test/mean_Q        | 14.449655   |
| test/success_rate  | 1.0         |
| train/episode      | 2960.0      |
| train/success_rate | 0.15        |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 74          |
| stats_g/mean       | 0.027350437 |
| stats_g/std        | 0.7979867   |
| stats_o/mean       | 0.014400225 |
| stats_o/std        | 0.60748273  |
| test/episode       | 1500.0      |
| test/mean_Q        | 15.356694   |
| test/success_rate  | 1.0         |
| train/episode      | 3000.0      |
| train/success_rate | 0.125       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_74.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
