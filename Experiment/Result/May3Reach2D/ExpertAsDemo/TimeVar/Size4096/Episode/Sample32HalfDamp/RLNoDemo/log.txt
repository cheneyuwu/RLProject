Logging to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo/
Launching the training process with 1 cpu core(s).
Setting log level to 2.
Using environment Reach2D with r scale down by 1.000000 shift by 0.500000 and max episode 0.000000
Skip demonstration training.
Demo policy file does not exit, cannot use demo policy.
*** her_params ***
k: 4
reward_fun: <function configure_her.<locals>.reward_fun at 0x7f690e1e36a8>
strategy: future
*** her_params ***
*** ddpg_params ***
Q_lr: 0.001
T: 42
action_l2: 0.5
aux_loss_weight: 0.0078
batch_size: 256
batch_size_demo: 128
buffer_size: 1000000
ca_ratio: 1
clip_obs: 200.0
clip_pos_returns: False
clip_return: 41.99999999999995
demo_strategy: none
gamma: 0.9761904761904762
hidden: 256
info: {'env_name': 'Reach2D', 'r_scale': 1.0, 'r_shift': 0.5, 'eps_length': 0}
input_dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
layers: 3
max_u: 2
norm_clip: 5
norm_eps: 0.01
num_demo: 1000
num_sample: 1
pi_lr: 0.001
polyak: 0.95
prm_loss_weight: 0.001
q_filter: 0
relative_goals: False
rollout_batch_size: 4
sample_transitions: <function make_sample_her_transitions.<locals>._sample_her_transitions at 0x7f690e1e3730>
scope: critic_demo
subtract_goals: <function simple_goal_subtract at 0x7f690e1df620>
*** ddpg_params ***
Configuring the replay buffer.
Preparing staging area for feeding data to the model.
Creating a DDPG agent with action space 2 x 2.

*** rollout_params ***
T: 42
compute_Q: False
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 0
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 4
use_demo_states: True
use_target_net: False
*** rollout_params ***
*** eval_params ***
T: 42
compute_Q: True
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 1
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 20
use_demo_states: False
use_target_net: False
*** eval_params ***
Training the RL agent.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 0          |
| stats_g/mean       | 0.41761994 |
| stats_g/std        | 2.1044807  |
| stats_o/mean       | 0.24221739 |
| stats_o/std        | 1.1958218  |
| test/episode       | 20.0       |
| test/mean_Q        | -1.7375607 |
| test/success_rate  | 0.0        |
| train/episode      | 40.0       |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_0.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 1          |
| stats_g/mean       | 0.25499937 |
| stats_g/std        | 2.0345485  |
| stats_o/mean       | 0.14623408 |
| stats_o/std        | 1.1655191  |
| test/episode       | 40.0       |
| test/mean_Q        | -2.3784335 |
| test/success_rate  | 0.0        |
| train/episode      | 80.0       |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 2           |
| stats_g/mean       | 0.03651746  |
| stats_g/std        | 1.8878597   |
| stats_o/mean       | 0.020219982 |
| stats_o/std        | 1.0960048   |
| test/episode       | 60.0        |
| test/mean_Q        | -2.312209   |
| test/success_rate  | 0.0         |
| train/episode      | 120.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_2.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 3            |
| stats_g/mean       | 0.0046641976 |
| stats_g/std        | 1.8385444    |
| stats_o/mean       | -0.006973518 |
| stats_o/std        | 1.0731282    |
| test/episode       | 80.0         |
| test/mean_Q        | -3.0359204   |
| test/success_rate  | 0.0          |
| train/episode      | 160.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 4             |
| stats_g/mean       | -0.0075535793 |
| stats_g/std        | 1.8009974     |
| stats_o/mean       | -0.015261615  |
| stats_o/std        | 1.056672      |
| test/episode       | 100.0         |
| test/mean_Q        | -2.774273     |
| test/success_rate  | 0.0           |
| train/episode      | 200.0         |
| train/success_rate | 0.0           |
--------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_4.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 5             |
| stats_g/mean       | 0.0058800247  |
| stats_g/std        | 1.7392507     |
| stats_o/mean       | -0.0073679863 |
| stats_o/std        | 1.0284898     |
| test/episode       | 120.0         |
| test/mean_Q        | -2.2911453    |
| test/success_rate  | 0.0           |
| train/episode      | 240.0         |
| train/success_rate | 0.0           |
--------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 6            |
| stats_g/mean       | 0.027497077  |
| stats_g/std        | 1.6743052    |
| stats_o/mean       | 0.0072629275 |
| stats_o/std        | 0.99692416   |
| test/episode       | 140.0        |
| test/mean_Q        | -1.9039054   |
| test/success_rate  | 0.05         |
| train/episode      | 280.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.05.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_6.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 7            |
| stats_g/mean       | 0.013001765  |
| stats_g/std        | 1.6225294    |
| stats_o/mean       | 0.0033005602 |
| stats_o/std        | 0.9747477    |
| test/episode       | 160.0        |
| test/mean_Q        | -1.1512889   |
| test/success_rate  | 0.0          |
| train/episode      | 320.0        |
| train/success_rate | 0.0          |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 8            |
| stats_g/mean       | 0.0064434893 |
| stats_g/std        | 1.5689311    |
| stats_o/mean       | 0.0017626975 |
| stats_o/std        | 0.9529425    |
| test/episode       | 180.0        |
| test/mean_Q        | -0.20608857  |
| test/success_rate  | 0.0          |
| train/episode      | 360.0        |
| train/success_rate | 0.0          |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_8.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 9            |
| stats_g/mean       | 0.014923524  |
| stats_g/std        | 1.515023     |
| stats_o/mean       | 0.0066370387 |
| stats_o/std        | 0.93095016   |
| test/episode       | 200.0        |
| test/mean_Q        | 0.0040985835 |
| test/success_rate  | 0.2          |
| train/episode      | 400.0        |
| train/success_rate | 0.025        |
-------------------------------------
New best success rate: 0.2.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 10           |
| stats_g/mean       | 0.00840679   |
| stats_g/std        | 1.471209     |
| stats_o/mean       | 0.0011829892 |
| stats_o/std        | 0.9122743    |
| test/episode       | 220.0        |
| test/mean_Q        | -0.10211131  |
| test/success_rate  | 0.0          |
| train/episode      | 440.0        |
| train/success_rate | 0.0          |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_10.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 11           |
| stats_g/mean       | 0.011752434  |
| stats_g/std        | 1.4306402    |
| stats_o/mean       | 0.0027877307 |
| stats_o/std        | 0.8953307    |
| test/episode       | 240.0        |
| test/mean_Q        | 0.69438857   |
| test/success_rate  | 0.4          |
| train/episode      | 480.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.4.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 12            |
| stats_g/mean       | -0.0033779982 |
| stats_g/std        | 1.394815      |
| stats_o/mean       | -0.004799883  |
| stats_o/std        | 0.88081706    |
| test/episode       | 260.0         |
| test/mean_Q        | 1.0062407     |
| test/success_rate  | 0.5           |
| train/episode      | 520.0         |
| train/success_rate | 0.05          |
--------------------------------------
New best success rate: 0.5.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_12.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 13            |
| stats_g/mean       | 0.005890878   |
| stats_g/std        | 1.3583369     |
| stats_o/mean       | 7.4160285e-05 |
| stats_o/std        | 0.86467874    |
| test/episode       | 280.0         |
| test/mean_Q        | 1.5062099     |
| test/success_rate  | 0.65          |
| train/episode      | 560.0         |
| train/success_rate | 0.025         |
--------------------------------------
New best success rate: 0.65.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 14            |
| stats_g/mean       | -0.0036478993 |
| stats_g/std        | 1.3249972     |
| stats_o/mean       | -0.0045699296 |
| stats_o/std        | 0.84986496    |
| test/episode       | 300.0         |
| test/mean_Q        | 1.6365417     |
| test/success_rate  | 0.7           |
| train/episode      | 600.0         |
| train/success_rate | 0.05          |
--------------------------------------
New best success rate: 0.7.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_14.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 15            |
| stats_g/mean       | -0.0023475327 |
| stats_g/std        | 1.2952639     |
| stats_o/mean       | -0.002492372  |
| stats_o/std        | 0.8369082     |
| test/episode       | 320.0         |
| test/mean_Q        | 1.3883417     |
| test/success_rate  | 0.4           |
| train/episode      | 640.0         |
| train/success_rate | 0.025         |
--------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
---------------------------------------
| epoch              | 16             |
| stats_g/mean       | 0.0025263708   |
| stats_g/std        | 1.2684584      |
| stats_o/mean       | -0.00040948344 |
| stats_o/std        | 0.8252088      |
| test/episode       | 340.0          |
| test/mean_Q        | 2.1398313      |
| test/success_rate  | 0.85           |
| train/episode      | 680.0          |
| train/success_rate | 0.05           |
---------------------------------------
New best success rate: 0.85.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_16.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 17           |
| stats_g/mean       | 0.0051084086 |
| stats_g/std        | 1.2416031    |
| stats_o/mean       | 0.001397925  |
| stats_o/std        | 0.81286573   |
| test/episode       | 360.0        |
| test/mean_Q        | 2.0029447    |
| test/success_rate  | 0.8          |
| train/episode      | 720.0        |
| train/success_rate | 0.05         |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 18           |
| stats_g/mean       | 0.009843043  |
| stats_g/std        | 1.2171036    |
| stats_o/mean       | 0.0038047708 |
| stats_o/std        | 0.8014641    |
| test/episode       | 380.0        |
| test/mean_Q        | 2.345081     |
| test/success_rate  | 0.95         |
| train/episode      | 760.0        |
| train/success_rate | 0.1          |
-------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_18.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 19           |
| stats_g/mean       | 0.011806653  |
| stats_g/std        | 1.1939135    |
| stats_o/mean       | 0.0052016666 |
| stats_o/std        | 0.7914018    |
| test/episode       | 400.0        |
| test/mean_Q        | 3.0362797    |
| test/success_rate  | 0.95         |
| train/episode      | 800.0        |
| train/success_rate | 0.075        |
-------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 20           |
| stats_g/mean       | 0.006573542  |
| stats_g/std        | 1.1725318    |
| stats_o/mean       | 0.0025377208 |
| stats_o/std        | 0.78148675   |
| test/episode       | 420.0        |
| test/mean_Q        | 2.6603673    |
| test/success_rate  | 1.0          |
| train/episode      | 840.0        |
| train/success_rate | 0.1          |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_20.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 21           |
| stats_g/mean       | 0.007280483  |
| stats_g/std        | 1.1544483    |
| stats_o/mean       | 0.0033199987 |
| stats_o/std        | 0.7727392    |
| test/episode       | 440.0        |
| test/mean_Q        | 3.349632     |
| test/success_rate  | 1.0          |
| train/episode      | 880.0        |
| train/success_rate | 0.175        |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 22           |
| stats_g/mean       | 0.006317192  |
| stats_g/std        | 1.138133     |
| stats_o/mean       | 0.0024038586 |
| stats_o/std        | 0.76605344   |
| test/episode       | 460.0        |
| test/mean_Q        | 3.0875514    |
| test/success_rate  | 1.0          |
| train/episode      | 920.0        |
| train/success_rate | 0.15         |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_22.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 23           |
| stats_g/mean       | 0.004778323  |
| stats_g/std        | 1.122709     |
| stats_o/mean       | 0.0015187813 |
| stats_o/std        | 0.75886357   |
| test/episode       | 480.0        |
| test/mean_Q        | 3.2350185    |
| test/success_rate  | 1.0          |
| train/episode      | 960.0        |
| train/success_rate | 0.15         |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 24           |
| stats_g/mean       | 0.008641087  |
| stats_g/std        | 1.1069397    |
| stats_o/mean       | 0.0037809873 |
| stats_o/std        | 0.75217414   |
| test/episode       | 500.0        |
| test/mean_Q        | 3.877914     |
| test/success_rate  | 1.0          |
| train/episode      | 1000.0       |
| train/success_rate | 0.075        |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_24.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
