Logging to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo/
Launching the training process with 1 cpu core(s).
Setting log level to 2.
Using environment Reach2DSparse with r scale down by 1.000000 shift by 0.000000 and max episode 0.000000
Skip demonstration training.
Demo policy file does not exit, cannot use demo policy.
*** her_params ***
k: 4
reward_fun: <function configure_her.<locals>.reward_fun at 0x7f5b8f8106a8>
strategy: future
*** her_params ***
*** ddpg_params ***
Q_lr: 0.001
T: 42
action_l2: 0.5
aux_loss_weight: 0.0078
batch_size: 256
batch_size_demo: 128
buffer_size: 1000000
ca_ratio: 1
clip_obs: 200.0
clip_pos_returns: False
clip_return: 41.99999999999995
demo_strategy: none
gamma: 0.9761904761904762
hidden: 256
info: {'env_name': 'Reach2DSparse', 'r_scale': 1.0, 'r_shift': 0.0, 'eps_length': 0}
input_dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
layers: 3
max_u: 2
norm_clip: 5
norm_eps: 0.01
num_demo: 1000
num_sample: 1
pi_lr: 0.001
polyak: 0.95
prm_loss_weight: 0.001
q_filter: 0
relative_goals: False
rollout_batch_size: 4
sample_transitions: <function make_sample_her_transitions.<locals>._sample_her_transitions at 0x7f5b8f810730>
scope: critic_demo
subtract_goals: <function simple_goal_subtract at 0x7f5b8f80c620>
*** ddpg_params ***
Configuring the replay buffer.
Preparing staging area for feeding data to the model.
Creating a DDPG agent with action space 2 x 2.

*** rollout_params ***
T: 42
compute_Q: False
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 0
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 4
use_demo_states: True
use_target_net: False
*** rollout_params ***
*** eval_params ***
T: 42
compute_Q: True
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 1
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 20
use_demo_states: False
use_target_net: False
*** eval_params ***
Training the RL agent.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 0          |
| stats_g/mean       | 0.49019754 |
| stats_g/std        | 1.9439287  |
| stats_o/mean       | 0.2821393  |
| stats_o/std        | 1.1133946  |
| test/episode       | 20.0       |
| test/mean_Q        | 0.10797955 |
| test/success_rate  | 0.0        |
| train/episode      | 40.0       |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_0.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 1           |
| stats_g/mean       | 0.22484809  |
| stats_g/std        | 2.0653005   |
| stats_o/mean       | 0.13082984  |
| stats_o/std        | 1.1894369   |
| test/episode       | 40.0        |
| test/mean_Q        | 0.041636545 |
| test/success_rate  | 0.0         |
| train/episode      | 80.0        |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 2           |
| stats_g/mean       | 0.04987283  |
| stats_g/std        | 1.9910207   |
| stats_o/mean       | 0.028246734 |
| stats_o/std        | 1.1592249   |
| test/episode       | 60.0        |
| test/mean_Q        | 0.10525989  |
| test/success_rate  | 0.0         |
| train/episode      | 120.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_2.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 3            |
| stats_g/mean       | 0.020254828  |
| stats_g/std        | 1.9956477    |
| stats_o/mean       | 0.0024730414 |
| stats_o/std        | 1.1626631    |
| test/episode       | 80.0         |
| test/mean_Q        | 0.02088128   |
| test/success_rate  | 0.0          |
| train/episode      | 160.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 4            |
| stats_g/mean       | 0.02415523   |
| stats_g/std        | 2.0121098    |
| stats_o/mean       | 0.0020072833 |
| stats_o/std        | 1.1684806    |
| test/episode       | 100.0        |
| test/mean_Q        | 0.05194699   |
| test/success_rate  | 0.0          |
| train/episode      | 200.0        |
| train/success_rate | 0.025        |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_4.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 5          |
| stats_g/mean       | 0.07150691 |
| stats_g/std        | 2.0454524  |
| stats_o/mean       | 0.03041865 |
| stats_o/std        | 1.1847693  |
| test/episode       | 120.0      |
| test/mean_Q        | 0.12831505 |
| test/success_rate  | 0.0        |
| train/episode      | 240.0      |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 6           |
| stats_g/mean       | 0.121550255 |
| stats_g/std        | 2.0253377   |
| stats_o/mean       | 0.05960755  |
| stats_o/std        | 1.1713616   |
| test/episode       | 140.0       |
| test/mean_Q        | 0.15943629  |
| test/success_rate  | 0.0         |
| train/episode      | 280.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_6.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 7           |
| stats_g/mean       | 0.11863545  |
| stats_g/std        | 2.01463     |
| stats_o/mean       | 0.063588604 |
| stats_o/std        | 1.1651495   |
| test/episode       | 160.0       |
| test/mean_Q        | 0.19732352  |
| test/success_rate  | 0.05        |
| train/episode      | 320.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.05.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 8          |
| stats_g/mean       | 0.13103344 |
| stats_g/std        | 2.0167801  |
| stats_o/mean       | 0.07028775 |
| stats_o/std        | 1.1665344  |
| test/episode       | 180.0      |
| test/mean_Q        | 0.72777665 |
| test/success_rate  | 0.2        |
| train/episode      | 360.0      |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.2.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_8.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 9          |
| stats_g/mean       | 0.15878221 |
| stats_g/std        | 2.0177903  |
| stats_o/mean       | 0.08641373 |
| stats_o/std        | 1.1677732  |
| test/episode       | 200.0      |
| test/mean_Q        | 0.85545295 |
| test/success_rate  | 0.2        |
| train/episode      | 400.0      |
| train/success_rate | 0.05       |
-----------------------------------
New best success rate: 0.2.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 10         |
| stats_g/mean       | 0.10798819 |
| stats_g/std        | 2.0259624  |
| stats_o/mean       | 0.05716274 |
| stats_o/std        | 1.1694367  |
| test/episode       | 220.0      |
| test/mean_Q        | 0.6739459  |
| test/success_rate  | 0.15       |
| train/episode      | 440.0      |
| train/success_rate | 0.1        |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_10.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 11          |
| stats_g/mean       | 0.09438147  |
| stats_g/std        | 2.0068817   |
| stats_o/mean       | 0.049113892 |
| stats_o/std        | 1.1592953   |
| test/episode       | 240.0       |
| test/mean_Q        | 1.0180713   |
| test/success_rate  | 0.25        |
| train/episode      | 480.0       |
| train/success_rate | 0.125       |
------------------------------------
New best success rate: 0.25.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 12          |
| stats_g/mean       | 0.093949944 |
| stats_g/std        | 2.000337    |
| stats_o/mean       | 0.049904373 |
| stats_o/std        | 1.1531329   |
| test/episode       | 260.0       |
| test/mean_Q        | 1.941136    |
| test/success_rate  | 0.35        |
| train/episode      | 520.0       |
| train/success_rate | 0.125       |
------------------------------------
New best success rate: 0.35.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_12.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 13          |
| stats_g/mean       | 0.080336966 |
| stats_g/std        | 1.9865073   |
| stats_o/mean       | 0.040962372 |
| stats_o/std        | 1.1454794   |
| test/episode       | 280.0       |
| test/mean_Q        | 1.365079    |
| test/success_rate  | 0.25        |
| train/episode      | 560.0       |
| train/success_rate | 0.125       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 14          |
| stats_g/mean       | 0.08174396  |
| stats_g/std        | 1.9791912   |
| stats_o/mean       | 0.044521026 |
| stats_o/std        | 1.1404448   |
| test/episode       | 300.0       |
| test/mean_Q        | 2.2655852   |
| test/success_rate  | 0.4         |
| train/episode      | 600.0       |
| train/success_rate | 0.2         |
------------------------------------
New best success rate: 0.4.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_14.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 15          |
| stats_g/mean       | 0.10977849  |
| stats_g/std        | 1.9797759   |
| stats_o/mean       | 0.061906777 |
| stats_o/std        | 1.1402713   |
| test/episode       | 320.0       |
| test/mean_Q        | 2.5148246   |
| test/success_rate  | 0.4         |
| train/episode      | 640.0       |
| train/success_rate | 0.05        |
------------------------------------
New best success rate: 0.4.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 16          |
| stats_g/mean       | 0.099405415 |
| stats_g/std        | 1.9746945   |
| stats_o/mean       | 0.055467837 |
| stats_o/std        | 1.1373845   |
| test/episode       | 340.0       |
| test/mean_Q        | 2.948405    |
| test/success_rate  | 0.45        |
| train/episode      | 680.0       |
| train/success_rate | 0.25        |
------------------------------------
New best success rate: 0.45.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_16.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 17          |
| stats_g/mean       | 0.093894355 |
| stats_g/std        | 1.9705081   |
| stats_o/mean       | 0.051939115 |
| stats_o/std        | 1.1360984   |
| test/episode       | 360.0       |
| test/mean_Q        | 3.8978274   |
| test/success_rate  | 0.55        |
| train/episode      | 720.0       |
| train/success_rate | 0.2         |
------------------------------------
New best success rate: 0.55.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 18         |
| stats_g/mean       | 0.08850098 |
| stats_g/std        | 1.9553329  |
| stats_o/mean       | 0.04848411 |
| stats_o/std        | 1.1280031  |
| test/episode       | 380.0      |
| test/mean_Q        | 2.1794946  |
| test/success_rate  | 0.3        |
| train/episode      | 760.0      |
| train/success_rate | 0.35       |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_18.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 19          |
| stats_g/mean       | 0.09636092  |
| stats_g/std        | 1.9409636   |
| stats_o/mean       | 0.053896025 |
| stats_o/std        | 1.1207225   |
| test/episode       | 400.0       |
| test/mean_Q        | 5.662755    |
| test/success_rate  | 0.7         |
| train/episode      | 800.0       |
| train/success_rate | 0.25        |
------------------------------------
New best success rate: 0.7.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 20         |
| stats_g/mean       | 0.08652939 |
| stats_g/std        | 1.9333543  |
| stats_o/mean       | 0.04839209 |
| stats_o/std        | 1.117205   |
| test/episode       | 420.0      |
| test/mean_Q        | 3.7692075  |
| test/success_rate  | 0.45       |
| train/episode      | 840.0      |
| train/success_rate | 0.25       |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_20.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 21         |
| stats_g/mean       | 0.09069314 |
| stats_g/std        | 1.9142294  |
| stats_o/mean       | 0.0509905  |
| stats_o/std        | 1.1070373  |
| test/episode       | 440.0      |
| test/mean_Q        | 6.5366664  |
| test/success_rate  | 0.75       |
| train/episode      | 880.0      |
| train/success_rate | 0.25       |
-----------------------------------
New best success rate: 0.75.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 22          |
| stats_g/mean       | 0.079178095 |
| stats_g/std        | 1.9046572   |
| stats_o/mean       | 0.04255078  |
| stats_o/std        | 1.103328    |
| test/episode       | 460.0       |
| test/mean_Q        | 5.024928    |
| test/success_rate  | 0.55        |
| train/episode      | 920.0       |
| train/success_rate | 0.375       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_22.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 23          |
| stats_g/mean       | 0.06891346  |
| stats_g/std        | 1.8906176   |
| stats_o/mean       | 0.036490828 |
| stats_o/std        | 1.0965538   |
| test/episode       | 480.0       |
| test/mean_Q        | 3.8173137   |
| test/success_rate  | 0.4         |
| train/episode      | 960.0       |
| train/success_rate | 0.3         |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 24          |
| stats_g/mean       | 0.07160201  |
| stats_g/std        | 1.8879571   |
| stats_o/mean       | 0.037842408 |
| stats_o/std        | 1.0953424   |
| test/episode       | 500.0       |
| test/mean_Q        | 7.163522    |
| test/success_rate  | 0.75        |
| train/episode      | 1000.0      |
| train/success_rate | 0.4         |
------------------------------------
New best success rate: 0.75.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_24.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 25         |
| stats_g/mean       | 0.07358906 |
| stats_g/std        | 1.8750687  |
| stats_o/mean       | 0.03969051 |
| stats_o/std        | 1.0883093  |
| test/episode       | 520.0      |
| test/mean_Q        | 6.5292726  |
| test/success_rate  | 0.65       |
| train/episode      | 1040.0     |
| train/success_rate | 0.475      |
-----------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 26         |
| stats_g/mean       | 0.07343303 |
| stats_g/std        | 1.8597393  |
| stats_o/mean       | 0.03971167 |
| stats_o/std        | 1.0805001  |
| test/episode       | 540.0      |
| test/mean_Q        | 7.6982746  |
| test/success_rate  | 0.75       |
| train/episode      | 1080.0     |
| train/success_rate | 0.3        |
-----------------------------------
New best success rate: 0.75.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_26.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 27          |
| stats_g/mean       | 0.07464753  |
| stats_g/std        | 1.8432815   |
| stats_o/mean       | 0.040738937 |
| stats_o/std        | 1.072406    |
| test/episode       | 560.0       |
| test/mean_Q        | 10.483033   |
| test/success_rate  | 0.95        |
| train/episode      | 1120.0      |
| train/success_rate | 0.325       |
------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 28          |
| stats_g/mean       | 0.06700491  |
| stats_g/std        | 1.8299198   |
| stats_o/mean       | 0.036373217 |
| stats_o/std        | 1.0663568   |
| test/episode       | 580.0       |
| test/mean_Q        | 10.447558   |
| test/success_rate  | 0.95        |
| train/episode      | 1160.0      |
| train/success_rate | 0.45        |
------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_28.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 29          |
| stats_g/mean       | 0.063078    |
| stats_g/std        | 1.8144064   |
| stats_o/mean       | 0.033928033 |
| stats_o/std        | 1.0585966   |
| test/episode       | 600.0       |
| test/mean_Q        | 9.749192    |
| test/success_rate  | 0.85        |
| train/episode      | 1200.0      |
| train/success_rate | 0.375       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 30          |
| stats_g/mean       | 0.05974477  |
| stats_g/std        | 1.803263    |
| stats_o/mean       | 0.031600665 |
| stats_o/std        | 1.0534332   |
| test/episode       | 620.0       |
| test/mean_Q        | 9.706171    |
| test/success_rate  | 0.85        |
| train/episode      | 1240.0      |
| train/success_rate | 0.3         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_30.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 31          |
| stats_g/mean       | 0.06345402  |
| stats_g/std        | 1.7860812   |
| stats_o/mean       | 0.034133192 |
| stats_o/std        | 1.0453368   |
| test/episode       | 640.0       |
| test/mean_Q        | 9.217146    |
| test/success_rate  | 0.8         |
| train/episode      | 1280.0      |
| train/success_rate | 0.475       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 32          |
| stats_g/mean       | 0.068053015 |
| stats_g/std        | 1.7732794   |
| stats_o/mean       | 0.03668292  |
| stats_o/std        | 1.039629    |
| test/episode       | 660.0       |
| test/mean_Q        | 11.2155695  |
| test/success_rate  | 0.9         |
| train/episode      | 1320.0      |
| train/success_rate | 0.575       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_32.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 33          |
| stats_g/mean       | 0.07331701  |
| stats_g/std        | 1.7610435   |
| stats_o/mean       | 0.039796915 |
| stats_o/std        | 1.0338062   |
| test/episode       | 680.0       |
| test/mean_Q        | 11.029067   |
| test/success_rate  | 0.9         |
| train/episode      | 1360.0      |
| train/success_rate | 0.3         |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 34          |
| stats_g/mean       | 0.072541    |
| stats_g/std        | 1.7435215   |
| stats_o/mean       | 0.039537974 |
| stats_o/std        | 1.0255901   |
| test/episode       | 700.0       |
| test/mean_Q        | 13.073805   |
| test/success_rate  | 1.0         |
| train/episode      | 1400.0      |
| train/success_rate | 0.425       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_34.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 35          |
| stats_g/mean       | 0.069973744 |
| stats_g/std        | 1.7275796   |
| stats_o/mean       | 0.03801258  |
| stats_o/std        | 1.0180668   |
| test/episode       | 720.0       |
| test/mean_Q        | 11.39402    |
| test/success_rate  | 0.85        |
| train/episode      | 1440.0      |
| train/success_rate | 0.325       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 36         |
| stats_g/mean       | 0.06982586 |
| stats_g/std        | 1.7128663  |
| stats_o/mean       | 0.03828837 |
| stats_o/std        | 1.0113592  |
| test/episode       | 740.0      |
| test/mean_Q        | 12.820199  |
| test/success_rate  | 0.95       |
| train/episode      | 1480.0     |
| train/success_rate | 0.55       |
-----------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_36.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 37          |
| stats_g/mean       | 0.06736505  |
| stats_g/std        | 1.7029378   |
| stats_o/mean       | 0.036835954 |
| stats_o/std        | 1.006192    |
| test/episode       | 760.0       |
| test/mean_Q        | 13.422763   |
| test/success_rate  | 1.0         |
| train/episode      | 1520.0      |
| train/success_rate | 0.4         |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 38          |
| stats_g/mean       | 0.064851105 |
| stats_g/std        | 1.6877663   |
| stats_o/mean       | 0.035510108 |
| stats_o/std        | 0.9993459   |
| test/episode       | 780.0       |
| test/mean_Q        | 13.289016   |
| test/success_rate  | 0.95        |
| train/episode      | 1560.0      |
| train/success_rate | 0.525       |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_38.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 39          |
| stats_g/mean       | 0.059884995 |
| stats_g/std        | 1.6727242   |
| stats_o/mean       | 0.032656036 |
| stats_o/std        | 0.9923569   |
| test/episode       | 800.0       |
| test/mean_Q        | 14.111508   |
| test/success_rate  | 1.0         |
| train/episode      | 1600.0      |
| train/success_rate | 0.475       |
------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLNoDemo//rl/policy_latest.pkl.
