Logging to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy/
Launching the training process with 1 cpu core(s).
Setting log level to 2.
Using environment Reach2DSparse with r scale down by 1.000000 shift by 0.000000 and max episode 0.000000
Skip demonstration training.
Will use provided policy file from /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/DemoCriticOnly/rl_demo_critic/policy_latest.pkl.
Creating a Demonstration NN.
Creating an Ensemble NN of sample x hidden x layer: 12 x 256 x 3.
*** her_params ***
k: 4
reward_fun: <function configure_her.<locals>.reward_fun at 0x7f2297518598>
strategy: future
*** her_params ***
*** ddpg_params ***
Q_lr: 0.001
T: 42
action_l2: 0.5
aux_loss_weight: 0.0078
batch_size: 256
batch_size_demo: 128
buffer_size: 1000000
ca_ratio: 1
clip_obs: 200.0
clip_pos_returns: False
clip_return: 41.99999999999995
demo_strategy: critic
gamma: 0.9761904761904762
hidden: 256
info: {'env_name': 'Reach2DSparse', 'r_scale': 1.0, 'r_shift': 0.0, 'eps_length': 0}
input_dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
layers: 3
max_u: 2
norm_clip: 5
norm_eps: 0.01
num_demo: 1000
num_sample: 1
pi_lr: 0.001
polyak: 0.95
prm_loss_weight: 0.001
q_filter: 0
relative_goals: False
rollout_batch_size: 4
sample_transitions: <function make_sample_her_transitions.<locals>._sample_her_transitions at 0x7f226027dbf8>
scope: ddpg
subtract_goals: <function simple_goal_subtract at 0x7f2297514620>
*** ddpg_params ***
Configuring the replay buffer.
Preparing staging area for feeding data to the model.
Creating a DDPG agent with action space 2 x 2.

*** rollout_params ***
T: 42
compute_Q: False
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 0
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 4
use_demo_states: True
use_target_net: False
*** rollout_params ***
*** eval_params ***
T: 42
compute_Q: True
dims: {'o': 4, 'u': 2, 'g': 2, 'info_is_success': 1}
exploit: 1
noise_eps: 0.2
random_eps: 0.3
rollout_batch_size: 20
use_demo_states: False
use_target_net: False
*** eval_params ***
Training the RL agent.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 0           |
| stats_g/mean       | 0.013779275 |
| stats_g/std        | 2.0764055   |
| stats_o/mean       | 0.03145616  |
| stats_o/std        | 1.1916966   |
| test/episode       | 20.0        |
| test/mean_Q        | 0.80391055  |
| test/success_rate  | 0.0         |
| train/episode      | 40.0        |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_0.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 1            |
| stats_g/mean       | -0.06545359  |
| stats_g/std        | 1.8206598    |
| stats_o/mean       | -0.029116897 |
| stats_o/std        | 1.0643132    |
| test/episode       | 40.0         |
| test/mean_Q        | 0.34599274   |
| test/success_rate  | 0.0          |
| train/episode      | 80.0         |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 2            |
| stats_g/mean       | -0.045193654 |
| stats_g/std        | 1.9937413    |
| stats_o/mean       | -0.018572068 |
| stats_o/std        | 1.1618904    |
| test/episode       | 60.0         |
| test/mean_Q        | 0.5746388    |
| test/success_rate  | 0.0          |
| train/episode      | 120.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_2.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 3            |
| stats_g/mean       | -0.037543587 |
| stats_g/std        | 1.9913341    |
| stats_o/mean       | -0.01329642  |
| stats_o/std        | 1.1582108    |
| test/episode       | 80.0         |
| test/mean_Q        | 1.1326365    |
| test/success_rate  | 0.0          |
| train/episode      | 160.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 4            |
| stats_g/mean       | -0.023446847 |
| stats_g/std        | 1.9981413    |
| stats_o/mean       | -0.009486033 |
| stats_o/std        | 1.1621606    |
| test/episode       | 100.0        |
| test/mean_Q        | 0.23447393   |
| test/success_rate  | 0.0          |
| train/episode      | 200.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_4.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 5             |
| stats_g/mean       | -0.0033243503 |
| stats_g/std        | 2.0424814     |
| stats_o/mean       | -0.0020889877 |
| stats_o/std        | 1.1812629     |
| test/episode       | 120.0         |
| test/mean_Q        | 3.4149384     |
| test/success_rate  | 0.05          |
| train/episode      | 240.0         |
| train/success_rate | 0.0           |
--------------------------------------
New best success rate: 0.05.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 6           |
| stats_g/mean       | 0.012431277 |
| stats_g/std        | 2.0188406   |
| stats_o/mean       | 0.004741268 |
| stats_o/std        | 1.1660455   |
| test/episode       | 140.0       |
| test/mean_Q        | 4.4932747   |
| test/success_rate  | 0.0         |
| train/episode      | 280.0       |
| train/success_rate | 0.0         |
------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_6.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 7            |
| stats_g/mean       | -0.016240912 |
| stats_g/std        | 1.9721599    |
| stats_o/mean       | -0.011086556 |
| stats_o/std        | 1.1404743    |
| test/episode       | 160.0        |
| test/mean_Q        | 2.526968     |
| test/success_rate  | 0.0          |
| train/episode      | 320.0        |
| train/success_rate | 0.0          |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 8            |
| stats_g/mean       | -0.034552313 |
| stats_g/std        | 1.9531455    |
| stats_o/mean       | -0.021907272 |
| stats_o/std        | 1.1294618    |
| test/episode       | 180.0        |
| test/mean_Q        | 6.348866     |
| test/success_rate  | 0.1          |
| train/episode      | 360.0        |
| train/success_rate | 0.0          |
-------------------------------------
New best success rate: 0.1.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_8.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 9           |
| stats_g/mean       | -0.02485331 |
| stats_g/std        | 1.9523668   |
| stats_o/mean       | -0.01654603 |
| stats_o/std        | 1.1275077   |
| test/episode       | 200.0       |
| test/mean_Q        | 5.630799    |
| test/success_rate  | 0.05        |
| train/episode      | 400.0       |
| train/success_rate | 0.025       |
------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 10           |
| stats_g/mean       | -0.024710016 |
| stats_g/std        | 1.9164232    |
| stats_o/mean       | -0.015710251 |
| stats_o/std        | 1.1093117    |
| test/episode       | 220.0        |
| test/mean_Q        | 7.138581     |
| test/success_rate  | 0.3          |
| train/episode      | 440.0        |
| train/success_rate | 0.125        |
-------------------------------------
New best success rate: 0.3.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_10.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 11          |
| stats_g/mean       | -0.0325873  |
| stats_g/std        | 1.8898654   |
| stats_o/mean       | -0.02106977 |
| stats_o/std        | 1.0945046   |
| test/episode       | 240.0       |
| test/mean_Q        | 9.628054    |
| test/success_rate  | 0.45        |
| train/episode      | 480.0       |
| train/success_rate | 0.1         |
------------------------------------
New best success rate: 0.45.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 12           |
| stats_g/mean       | -0.013880724 |
| stats_g/std        | 1.8588455    |
| stats_o/mean       | -0.010237806 |
| stats_o/std        | 1.0777838    |
| test/episode       | 260.0        |
| test/mean_Q        | 8.257049     |
| test/success_rate  | 0.3          |
| train/episode      | 520.0        |
| train/success_rate | 0.225        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_12.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 13           |
| stats_g/mean       | -0.025832314 |
| stats_g/std        | 1.8413609    |
| stats_o/mean       | -0.017545175 |
| stats_o/std        | 1.068598     |
| test/episode       | 280.0        |
| test/mean_Q        | 14.149993    |
| test/success_rate  | 0.75         |
| train/episode      | 560.0        |
| train/success_rate | 0.3          |
-------------------------------------
New best success rate: 0.75.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 14           |
| stats_g/mean       | -0.024194084 |
| stats_g/std        | 1.836571     |
| stats_o/mean       | -0.015243873 |
| stats_o/std        | 1.0657588    |
| test/episode       | 300.0        |
| test/mean_Q        | 13.644599    |
| test/success_rate  | 0.55         |
| train/episode      | 600.0        |
| train/success_rate | 0.275        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_14.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 15           |
| stats_g/mean       | -0.024137411 |
| stats_g/std        | 1.8231778    |
| stats_o/mean       | -0.014816083 |
| stats_o/std        | 1.0581647    |
| test/episode       | 320.0        |
| test/mean_Q        | 11.398688    |
| test/success_rate  | 0.55         |
| train/episode      | 640.0        |
| train/success_rate | 0.4          |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 16           |
| stats_g/mean       | -0.019919192 |
| stats_g/std        | 1.813582     |
| stats_o/mean       | -0.012395803 |
| stats_o/std        | 1.0546079    |
| test/episode       | 340.0        |
| test/mean_Q        | 14.833279    |
| test/success_rate  | 0.65         |
| train/episode      | 680.0        |
| train/success_rate | 0.325        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_16.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 17           |
| stats_g/mean       | -0.023620127 |
| stats_g/std        | 1.7918289    |
| stats_o/mean       | -0.014571801 |
| stats_o/std        | 1.0444093    |
| test/episode       | 360.0        |
| test/mean_Q        | 9.2920475    |
| test/success_rate  | 0.45         |
| train/episode      | 720.0        |
| train/success_rate | 0.325        |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 18           |
| stats_g/mean       | -0.019962328 |
| stats_g/std        | 1.805767     |
| stats_o/mean       | -0.012707436 |
| stats_o/std        | 1.0521963    |
| test/episode       | 380.0        |
| test/mean_Q        | 14.3849125   |
| test/success_rate  | 0.6          |
| train/episode      | 760.0        |
| train/success_rate | 0.225        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_18.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 19           |
| stats_g/mean       | -0.022825163 |
| stats_g/std        | 1.7932892    |
| stats_o/mean       | -0.014460814 |
| stats_o/std        | 1.0461156    |
| test/episode       | 400.0        |
| test/mean_Q        | 10.150815    |
| test/success_rate  | 0.4          |
| train/episode      | 800.0        |
| train/success_rate | 0.35         |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 20            |
| stats_g/mean       | -0.010220762  |
| stats_g/std        | 1.7681422     |
| stats_o/mean       | -0.0072041894 |
| stats_o/std        | 1.0330575     |
| test/episode       | 420.0         |
| test/mean_Q        | 10.628118     |
| test/success_rate  | 0.5           |
| train/episode      | 840.0         |
| train/success_rate | 0.45          |
--------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_20.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 21           |
| stats_g/mean       | -0.010349756 |
| stats_g/std        | 1.7583323    |
| stats_o/mean       | -0.007816296 |
| stats_o/std        | 1.0276624    |
| test/episode       | 440.0        |
| test/mean_Q        | 13.6098      |
| test/success_rate  | 0.55         |
| train/episode      | 880.0        |
| train/success_rate | 0.35         |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 22           |
| stats_g/mean       | -0.025845323 |
| stats_g/std        | 1.7553971    |
| stats_o/mean       | -0.016805062 |
| stats_o/std        | 1.026882     |
| test/episode       | 460.0        |
| test/mean_Q        | 20.619118    |
| test/success_rate  | 0.85         |
| train/episode      | 920.0        |
| train/success_rate | 0.3          |
-------------------------------------
New best success rate: 0.85.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_22.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 23           |
| stats_g/mean       | -0.022964451 |
| stats_g/std        | 1.7374045    |
| stats_o/mean       | -0.014919015 |
| stats_o/std        | 1.0176346    |
| test/episode       | 480.0        |
| test/mean_Q        | 17.593918    |
| test/success_rate  | 0.7          |
| train/episode      | 960.0        |
| train/success_rate | 0.525        |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 24           |
| stats_g/mean       | -0.017064186 |
| stats_g/std        | 1.724891     |
| stats_o/mean       | -0.011931441 |
| stats_o/std        | 1.0128108    |
| test/episode       | 500.0        |
| test/mean_Q        | 16.2115      |
| test/success_rate  | 0.6          |
| train/episode      | 1000.0       |
| train/success_rate | 0.45         |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_24.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 25           |
| stats_g/mean       | -0.022068039 |
| stats_g/std        | 1.7183678    |
| stats_o/mean       | -0.013861956 |
| stats_o/std        | 1.0091693    |
| test/episode       | 520.0        |
| test/mean_Q        | 21.182308    |
| test/success_rate  | 0.85         |
| train/episode      | 1040.0       |
| train/success_rate | 0.45         |
-------------------------------------
New best success rate: 0.85.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 26           |
| stats_g/mean       | -0.025739253 |
| stats_g/std        | 1.7123921    |
| stats_o/mean       | -0.015707366 |
| stats_o/std        | 1.0066413    |
| test/episode       | 540.0        |
| test/mean_Q        | 17.871815    |
| test/success_rate  | 0.75         |
| train/episode      | 1080.0       |
| train/success_rate | 0.5          |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_26.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
------------------------------------
| epoch              | 27          |
| stats_g/mean       | -0.02531537 |
| stats_g/std        | 1.7012826   |
| stats_o/mean       | -0.01610073 |
| stats_o/std        | 1.0012163   |
| test/episode       | 560.0       |
| test/mean_Q        | 20.59254    |
| test/success_rate  | 0.85        |
| train/episode      | 1120.0      |
| train/success_rate | 0.55        |
------------------------------------
New best success rate: 0.85.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 28           |
| stats_g/mean       | -0.017376656 |
| stats_g/std        | 1.6858354    |
| stats_o/mean       | -0.011064945 |
| stats_o/std        | 0.99451846   |
| test/episode       | 580.0        |
| test/mean_Q        | 18.242723    |
| test/success_rate  | 0.8          |
| train/episode      | 1160.0       |
| train/success_rate | 0.525        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_28.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 29           |
| stats_g/mean       | -0.024422865 |
| stats_g/std        | 1.6759663    |
| stats_o/mean       | -0.01565121  |
| stats_o/std        | 0.99018526   |
| test/episode       | 600.0        |
| test/mean_Q        | 19.49126     |
| test/success_rate  | 0.8          |
| train/episode      | 1200.0       |
| train/success_rate | 0.525        |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 30           |
| stats_g/mean       | -0.024192682 |
| stats_g/std        | 1.6536487    |
| stats_o/mean       | -0.015587764 |
| stats_o/std        | 0.9795036    |
| test/episode       | 620.0        |
| test/mean_Q        | 21.222387    |
| test/success_rate  | 0.8          |
| train/episode      | 1240.0       |
| train/success_rate | 0.675        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_30.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 31           |
| stats_g/mean       | -0.0229275   |
| stats_g/std        | 1.6423659    |
| stats_o/mean       | -0.014999831 |
| stats_o/std        | 0.9739218    |
| test/episode       | 640.0        |
| test/mean_Q        | 23.865503    |
| test/success_rate  | 0.9          |
| train/episode      | 1280.0       |
| train/success_rate | 0.675        |
-------------------------------------
New best success rate: 0.9.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 32           |
| stats_g/mean       | -0.023621866 |
| stats_g/std        | 1.6262375    |
| stats_o/mean       | -0.015415522 |
| stats_o/std        | 0.966324     |
| test/episode       | 660.0        |
| test/mean_Q        | 20.78656     |
| test/success_rate  | 0.8          |
| train/episode      | 1320.0       |
| train/success_rate | 0.575        |
-------------------------------------
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_32.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-----------------------------------
| epoch              | 33         |
| stats_g/mean       | -0.0246046 |
| stats_g/std        | 1.6137551  |
| stats_o/mean       | -0.0159924 |
| stats_o/std        | 0.96014607 |
| test/episode       | 680.0      |
| test/mean_Q        | 26.207762  |
| test/success_rate  | 0.95       |
| train/episode      | 1360.0     |
| train/success_rate | 0.675      |
-----------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 34           |
| stats_g/mean       | -0.024219977 |
| stats_g/std        | 1.6010934    |
| stats_o/mean       | -0.01582474  |
| stats_o/std        | 0.9542061    |
| test/episode       | 700.0        |
| test/mean_Q        | 27.499807    |
| test/success_rate  | 0.95         |
| train/episode      | 1400.0       |
| train/success_rate | 0.55         |
-------------------------------------
New best success rate: 0.95.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_34.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 35           |
| stats_g/mean       | -0.022261098 |
| stats_g/std        | 1.583666     |
| stats_o/mean       | -0.014840804 |
| stats_o/std        | 0.94589937   |
| test/episode       | 720.0        |
| test/mean_Q        | 21.647787    |
| test/success_rate  | 0.9          |
| train/episode      | 1440.0       |
| train/success_rate | 0.75         |
-------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 36           |
| stats_g/mean       | -0.020257061 |
| stats_g/std        | 1.5683634    |
| stats_o/mean       | -0.013077218 |
| stats_o/std        | 0.939366     |
| test/episode       | 740.0        |
| test/mean_Q        | 24.304617    |
| test/success_rate  | 1.0          |
| train/episode      | 1480.0       |
| train/success_rate | 0.725        |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_36.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
--------------------------------------
| epoch              | 37            |
| stats_g/mean       | -0.022073846  |
| stats_g/std        | 1.5511327     |
| stats_o/mean       | -0.0142669305 |
| stats_o/std        | 0.9309746     |
| test/episode       | 760.0         |
| test/mean_Q        | 23.634472     |
| test/success_rate  | 0.9           |
| train/episode      | 1520.0        |
| train/success_rate | 0.775         |
--------------------------------------
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 38           |
| stats_g/mean       | -0.024285778 |
| stats_g/std        | 1.53355      |
| stats_o/mean       | -0.015452776 |
| stats_o/std        | 0.92270195   |
| test/episode       | 780.0        |
| test/mean_Q        | 28.681652    |
| test/success_rate  | 1.0          |
| train/episode      | 1560.0       |
| train/success_rate | 0.675        |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving periodic policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_38.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
DDPG.check_train -> rl variance 0.0
-------------------------------------
| epoch              | 39           |
| stats_g/mean       | -0.023124002 |
| stats_g/std        | 1.52076      |
| stats_o/mean       | -0.014433883 |
| stats_o/std        | 0.9170339    |
| test/episode       | 800.0        |
| test/mean_Q        | 27.33201     |
| test/success_rate  | 1.0          |
| train/episode      | 1600.0       |
| train/success_rate | 0.525        |
-------------------------------------
New best success rate: 1.0.
Saving policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_best.pkl.
Saving latest policy to /home/yuchen/Desktop/RLProject/Experiment/Result/Temp/RLDemoCriticPolicy//rl/policy_latest.pkl.
